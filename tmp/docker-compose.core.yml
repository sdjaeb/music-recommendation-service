services:
  #################################
  # Core Databases & Messaging    #
  #################################

  # PostgreSQL: Central relational database.
  # Used by: Airflow (metadata store), Superset (metadata store).
  postgres:
    image: postgres:13 # Stable PostgreSQL version
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER_FILE: /run/secrets/postgres_user
      POSTGRES_PASSWORD_FILE: /run/secrets/postgres_pass
      POSTGRES_DB: airflow # Default database for Airflow
    secrets:
      - postgres_user
      - postgres_pass
      - superset_db_user
      - superset_db_pass
      - dbt_db_user
      - dbt_db_pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres-init:/docker-entrypoint-initdb.d # Script to create Superset DB on init
    networks:
      - data_platform_network
    healthcheck:
      test: ["CMD-SHELL", "bash -c '</dev/tcp/localhost/5432' || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: '512m'

  # Redis: In-memory data store.
  # Used by: Airflow (Celery message broker), Superset (caching).
  redis:
    image: redis:6.2-alpine # Lightweight and stable Redis version
    container_name: redis
    restart: always
    command: redis-server --requirepass $(cat /run/secrets/redis_pass) --appendonly yes
    secrets:
      - redis_pass
    networks:
      - data_platform_network
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "$(cat /run/secrets/redis_pass)", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: '128m'

  # Zookeeper: Coordination service required for Kafka.
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - data_platform_network
    healthcheck:
      test: ["CMD-SHELL", "echo 'ruok' | nc localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: '256m'

  # Kafka: Distributed event streaming platform.
  # Used for: Real-time data ingestion from FastAPI and consumption by Spark Streaming.
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    ports:
      - "9092:9092" # External port for Kafka clients
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_HEAP_OPTS: "-Xms512M -Xmx512M"
    depends_on:
      zookeeper:
        condition: service_healthy
    networks:
      - data_platform_network
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:29092 --list"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: '1g'

  # kcat (formerly kafkacat) - Kafka swiss-army-knife
  kcat:
    image: edenhill/kcat:1.7.1
    platform: linux/amd64
    container_name: kcat
    restart: unless-stopped
    command: ["sleep", "infinity"] # Keep the container running so we can exec into it
    networks:
      - data_platform_network
    depends_on:
      - kafka

  # MinIO: S3-compatible object storage.
  # Used as: The data lake for raw, curated, and processed data layers.
  minio:
    image: minio/minio:latest
    container_name: minio
    restart: always
    ports:
      - "9000:9000" # API port
      - "9001:9001" # Console UI port
    environment:
      MINIO_ROOT_USER_FILE: /run/secrets/minio_user
      MINIO_ROOT_PASSWORD_FILE: /run/secrets/minio_pass
    secrets:
      - minio_user
      - minio_pass
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    networks:
      - data_platform_network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: '512m'
