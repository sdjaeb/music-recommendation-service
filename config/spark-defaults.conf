# Default Spark configuration for the Data Platform

# --- Core Spark Settings ---
spark.master                     spark://spark-master:7077
spark.eventLog.enabled           true
spark.eventLog.dir               file:///opt/bitnami/spark/events
spark.history.fs.logDirectory    file:///opt/bitnami/spark/events

# --- Spark SQL & Thrift Server Settings ---
spark.sql.extensions                           io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog                org.apache.spark.sql.delta.catalog.DeltaCatalog
spark.sql.thriftserver.arrow.enabled           true
spark.hadoop.hive.server2.thrift.bind.host     0.0.0.0
spark.hadoop.hive.server2.enable.doAs          false
spark.hadoop.hive.server2.transport.mode       binary
spark.hadoop.hive.server2.authentication       NONE

# --- Package Management ---
# Comma-separated list of Maven coordinates for required packages.
spark.jars.packages              io.delta:delta-spark_2.12:3.2.0,org.apache.hadoop:hadoop-aws:3.3.4

# --- S3/MinIO Configuration ---
# This section configures Spark to connect to the MinIO data lake.
spark.hadoop.fs.s3a.endpoint                http://minio:9000
spark.hadoop.fs.s3a.access.key              minioadmin
spark.hadoop.fs.s3a.secret.key              minioadmin
spark.hadoop.fs.s3a.path.style.access       true
spark.hadoop.fs.s3a.impl                    org.apache.hadoop.fs.s3a.S3AFileSystem