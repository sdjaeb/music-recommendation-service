# docker-compose.test.yml
# This Docker Compose file defines a stripped-down set of services specifically
# for running integration tests. It includes only the essential components
# required for end-to-end data flow validation (FastAPI -> Kafka -> Spark -> MinIO).
# It uses separate volumes and environment variables to avoid conflicts with
# the main development environment.

version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: test-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    healthcheck:
      test: ["CMD", "sh", "-c", "echo stat | nc localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: test-kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092" # Expose for host-based test runners (e.g., pytest)
      - "29092:29092" # Internal Docker network listener
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_DELETE_TOPIC_ENABLE: "true" # Allow topic deletion for clean tests
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:29092 --list"]
      interval: 10s
      timeout: 5s
      retries: 5

  minio:
    image: minio/minio:latest
    container_name: test-minio
    ports:
      - "9000:9000" # MinIO API port
    environment:
      MINIO_ROOT_USER: test_user # Specific credentials for testing
      MINIO_ROOT_PASSWORD: test_password
    volumes:
      - test-minio-data:/data # Separate persistent volume for test data
    command: server /data --console-address ":9001" # Console UI on 9001, but not directly exposed by default
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  fastapi_ingestor:
    build: ./fastapi_app # Build from your FastAPI app source
    container_name: test-fastapi-ingestor
    ports:
      - "8000:8000" # Expose FastAPI API port for test calls
    environment:
      KAFKA_BROKER: kafka:29092 # Use Kafka service name for internal Docker communication
      KAFKA_TOPIC_FINANCIAL: raw_financial_transactions_test # Specific topic for testing
      KAFKA_TOPIC_INSURANCE: raw_insurance_claims_test # Specific topic for testing
      # No OpenTelemetry setup for basic integration tests to keep it lighter
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 5s
      timeout: 3s
      retries: 5

  # Spark service for integration testing.
  # This worker is configured to run in 'local[*]' mode within the container,
  # simplifying test setup as it doesn't need a separate master.
  spark-test-runner:
    image: bitnami/spark:3.5.0
    container_name: test-spark-runner
    depends_on:
      kafka:
        condition: service_healthy
      minio:
        condition: service_healthy
    environment:
      SPARK_MASTER_URL: "local[*]" # Run Spark in local mode for testing
      KAFKA_BROKER: kafka:29092
      MINIO_HOST: minio
      MINIO_ACCESS_KEY: test_user
      MINIO_SECRET_KEY: test_password
    volumes:
      - ./pyspark_jobs:/opt/bitnami/spark/jobs # Mount PySpark jobs for test execution
      - test-spark-output:/tmp/spark_output # Volume for Spark job output during tests
    command: ["tail", "-f", "/dev/null"] # Keep container running for `docker exec` commands
    # No exposed ports needed unless you want to inspect Spark UI during debugging tests

volumes:
  test-minio-data:
    driver: local
  test-spark-output:
    driver: local
